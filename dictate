#!/usr/bin/env python3
"""Push-to-talk dictation using faster-whisper and evdev.

Modes:
  dictate              - push-to-talk daemon (hold key to record, clipboard output)
  dictate --serve      - background daemon (model stays loaded, listens on socket)
  dictate --once       - send record request to daemon, print transcription to stdout
"""

import argparse
import json
import os
import signal
import socket
import subprocess
import sys
from pathlib import Path
from selectors import DefaultSelector, EVENT_READ

import evdev
import numpy as np
import sounddevice as sd
from evdev import ecodes
from faster_whisper import WhisperModel

SAMPLE_RATE = 16000
SOCK_PATH = os.path.expanduser("~/.local/share/dictate/dictate.sock")
PID_PATH = os.path.expanduser("~/.local/share/dictate/dictate.pid")


def find_audio_device():
    """Find the best input device, preferring pipewire."""
    devices = sd.query_devices()
    for i, dev in enumerate(devices):
        if dev['max_input_channels'] > 0 and 'pipewire' in dev['name'].lower():
            return i
    return None


def has_cuda():
    try:
        import ctranslate2
        return len(ctranslate2.get_supported_compute_types("cuda")) > 0
    except Exception:
        return False


def pick_defaults():
    if has_cuda():
        return "cuda", "int8", "medium"
    else:
        return "cpu", "int8", "small"


def find_keyboards():
    found = []
    devices = [evdev.InputDevice(path) for path in evdev.list_devices()]
    for dev in devices:
        caps = dev.capabilities(verbose=True)
        for (etype, _), codes in caps.items():
            if etype == "EV_KEY":
                key_names = [name for name, _ in codes]
                if "KEY_A" in key_names and "KEY_ENTER" in key_names:
                    found.append(dev)
                    break
    return found


def list_devices():
    devices = [evdev.InputDevice(path) for path in evdev.list_devices()]
    for dev in devices:
        if ecodes.EV_KEY in dev.capabilities():
            print(f"  {dev.path}: {dev.name}")


def record_until_silence(audio_dev, silence_secs=3):
    """Record audio, stop after silence_secs of silence following speech."""
    # Calibrate
    calibration_rms = []

    def cal_cb(indata, frames, time_info, status):
        calibration_rms.append(np.sqrt(np.mean(indata ** 2)))

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=cal_cb, device=audio_dev,
    )
    stream.start()
    sd.sleep(500)
    stream.stop()
    stream.close()

    ambient = np.mean(calibration_rms) if calibration_rms else 0.01
    speech_threshold = ambient * 1.5 + 0.01

    # Record
    audio_buffer = []
    is_recording = True
    speech_detected = False
    silence_frames = 0
    silence_limit = int(silence_secs / 0.064)  # ~64ms per callback

    def audio_cb(indata, frames, time_info, status):
        nonlocal speech_detected, silence_frames, is_recording
        audio_buffer.append(indata.copy())
        rms = np.sqrt(np.mean(indata ** 2))
        if rms > speech_threshold:
            speech_detected = True
            silence_frames = 0
        elif speech_detected:
            silence_frames += 1
            if silence_frames >= silence_limit:
                is_recording = False

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=audio_cb, device=audio_dev,
    )
    stream.start()

    try:
        while is_recording:
            sd.sleep(100)
    except KeyboardInterrupt:
        pass
    finally:
        stream.stop()
        stream.close()

    if not audio_buffer or not speech_detected:
        return None

    return np.concatenate(audio_buffer, axis=0).flatten()


# ── Daemon (--serve) ──────────────────────────────────────────────

def serve(model, language, audio_dev):
    """Run as a background daemon. Listen on Unix socket for record requests."""
    Path(SOCK_PATH).parent.mkdir(parents=True, exist_ok=True)
    if os.path.exists(SOCK_PATH):
        os.unlink(SOCK_PATH)

    # Write PID file
    with open(PID_PATH, "w") as f:
        f.write(str(os.getpid()))

    server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    server.bind(SOCK_PATH)
    server.listen(1)

    def cleanup(signum=None, frame=None):
        server.close()
        for p in (SOCK_PATH, PID_PATH):
            if os.path.exists(p):
                os.unlink(p)
        sys.exit(0)

    signal.signal(signal.SIGTERM, cleanup)
    signal.signal(signal.SIGINT, cleanup)

    print(f"Daemon ready. PID={os.getpid()}, socket={SOCK_PATH}")
    print("Waiting for requests...\n")

    try:
        while True:
            conn, _ = server.accept()
            try:
                data = conn.recv(1024).decode().strip()
                req = json.loads(data) if data else {}
                silence = req.get("silence_secs", 3)

                print("● Recording...", end="", flush=True)
                audio = record_until_silence(audio_dev, silence_secs=silence)

                if audio is None:
                    print(" (no speech)\n")
                    conn.sendall(json.dumps({"text": ""}).encode())
                    continue

                duration = len(audio) / SAMPLE_RATE
                print(f" [{duration:.1f}s] transcribing...", end="", flush=True)

                lang = req.get("language", language)
                segments, _ = model.transcribe(audio, language=lang)
                text = " ".join(seg.text for seg in segments).strip()

                print(f" done.\n> {text}\n")
                conn.sendall(json.dumps({"text": text}).encode())
            except Exception as e:
                print(f" error: {e}\n")
                try:
                    conn.sendall(json.dumps({"error": str(e)}).encode())
                except Exception:
                    pass
            finally:
                conn.close()
    finally:
        cleanup()


# ── Client (--once) ───────────────────────────────────────────────

def client_once(language):
    """Send a record request to the daemon and print the result."""
    if not os.path.exists(SOCK_PATH):
        print("Daemon not running. Start it with: dictate --serve", file=sys.stderr)
        sys.exit(1)

    sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    sock.connect(SOCK_PATH)
    sock.sendall(json.dumps({"language": language}).encode())

    # Read full response
    chunks = []
    while True:
        chunk = sock.recv(4096)
        if not chunk:
            break
        chunks.append(chunk)
    sock.close()

    resp = json.loads(b"".join(chunks).decode())
    text = resp.get("text", "")
    if text:
        print(text)


# ── Push-to-talk (default) ───────────────────────────────────────

def push_to_talk(model, language, key_code, key_name, keyboards, audio_dev):
    audio_buffer = []
    is_recording = False

    def audio_callback(indata, frames, time_info, status):
        if is_recording:
            audio_buffer.append(indata.copy())

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=audio_callback, device=audio_dev,
    )
    stream.start()

    print("Listening on:")
    for kbd in keyboards:
        print(f"  {kbd.name} ({kbd.path})")
    print(f"Hold [{key_name}] to record, release to transcribe.")
    print(f"Ctrl+C to quit.\n")

    selector = DefaultSelector()
    for kbd in keyboards:
        selector.register(kbd, EVENT_READ)

    try:
        while True:
            for sel_key, _ in selector.select():
                dev = sel_key.fileobj
                for event in dev.read():
                    if event.type != ecodes.EV_KEY:
                        continue
                    key_event = evdev.categorize(event)
                    if key_event.scancode != key_code:
                        continue

                    if key_event.keystate == evdev.KeyEvent.key_down and not is_recording:
                        audio_buffer.clear()
                        is_recording = True
                        print("● Recording...", end="", flush=True)

                    elif key_event.keystate == evdev.KeyEvent.key_up and is_recording:
                        is_recording = False

                        if not audio_buffer:
                            print(" (no audio captured)\n")
                            continue

                        audio = np.concatenate(audio_buffer, axis=0).flatten()
                        duration = len(audio) / SAMPLE_RATE
                        print(f" [{duration:.1f}s] transcribing...", end="", flush=True)

                        segments, _ = model.transcribe(audio, language=language)
                        text = " ".join(seg.text for seg in segments).strip()

                        if text:
                            subprocess.run(["wl-copy", text])
                            print(f" done. [copied]\n> {text}\n")
                        else:
                            print(" (no speech detected)\n")

    except KeyboardInterrupt:
        print("\nStopping.")
    finally:
        stream.stop()
        stream.close()


def main():
    hw_device, hw_compute, hw_model = pick_defaults()

    parser = argparse.ArgumentParser(description="Push-to-talk dictation")
    parser.add_argument("--key", default="RIGHTCTRL",
        help="Trigger key (default: RIGHTCTRL)")
    parser.add_argument("--model", default=hw_model,
        help=f"Whisper model (default: {hw_model})")
    parser.add_argument("--device", help="Input device path")
    parser.add_argument("--list-devices", action="store_true")
    parser.add_argument("--language", default="en", help="Language (default: en)")
    parser.add_argument("--cpu", action="store_true", help="Force CPU")
    parser.add_argument("--serve", action="store_true",
        help="Run as background daemon (model stays loaded)")
    parser.add_argument("--once", action="store_true",
        help="Send record request to daemon, print result, exit")
    parser.add_argument("--stop", action="store_true",
        help="Stop the running daemon")
    args = parser.parse_args()

    if args.list_devices:
        list_devices()
        return

    # --once: just talk to daemon
    if args.once:
        client_once(args.language)
        return

    # --stop: kill daemon
    if args.stop:
        if os.path.exists(PID_PATH):
            pid = int(open(PID_PATH).read().strip())
            os.kill(pid, signal.SIGTERM)
            print(f"Stopped daemon (PID {pid}).")
        else:
            print("No daemon running.")
        return

    # Hardware setup
    if args.cpu:
        device, compute = "cpu", "int8"
    else:
        device, compute = hw_device, hw_compute

    audio_dev = find_audio_device()

    print(f"Loading whisper model '{args.model}' on {device} ({compute})...")
    model = WhisperModel(args.model, device=device, compute_type=compute)

    # --serve: daemon mode
    if args.serve:
        serve(model, args.language, audio_dev)
        return

    # Default: push-to-talk
    key_name = f"KEY_{args.key.upper()}"
    key_code = getattr(ecodes, key_name, None)
    if key_code is None:
        print(f"Unknown key: {key_name}")
        sys.exit(1)

    if args.device:
        keyboards = [evdev.InputDevice(args.device)]
    else:
        keyboards = find_keyboards()
        if not keyboards:
            print("No keyboard found. Try --list-devices and --device.")
            sys.exit(1)

    push_to_talk(model, args.language, key_code, args.key.upper(), keyboards, audio_dev)


if __name__ == "__main__":
    main()
