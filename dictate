#!/usr/bin/env python3
"""Push-to-talk dictation using faster-whisper and evdev."""

import argparse
import subprocess
import sys
from selectors import DefaultSelector, EVENT_READ

import evdev
import numpy as np
import sounddevice as sd
from evdev import ecodes
from faster_whisper import WhisperModel

SAMPLE_RATE = 16000


def find_audio_device():
    """Find the best input device, preferring pipewire."""
    devices = sd.query_devices()
    for i, dev in enumerate(devices):
        if dev['max_input_channels'] > 0 and 'pipewire' in dev['name'].lower():
            return i
    return None  # use system default


def has_cuda():
    """Check if CUDA is available via ctranslate2."""
    try:
        import ctranslate2
        return len(ctranslate2.get_supported_compute_types("cuda")) > 0
    except Exception:
        return False


def pick_defaults():
    """Auto-detect hardware and return (device, compute_type, model)."""
    if has_cuda():
        return "cuda", "int8", "medium"
    else:
        return "cpu", "int8", "small"


def find_keyboards():
    """Find all keyboard devices (those with letter keys)."""
    found = []
    devices = [evdev.InputDevice(path) for path in evdev.list_devices()]
    for dev in devices:
        caps = dev.capabilities(verbose=True)
        for (etype, _), codes in caps.items():
            if etype == "EV_KEY":
                key_names = [name for name, _ in codes]
                if "KEY_A" in key_names and "KEY_ENTER" in key_names:
                    found.append(dev)
                    break
    return found


def list_devices():
    """List all input devices that have keys."""
    devices = [evdev.InputDevice(path) for path in evdev.list_devices()]
    for dev in devices:
        if ecodes.EV_KEY in dev.capabilities():
            print(f"  {dev.path}: {dev.name}")


def run_once(model, language):
    """Record until silence, transcribe once, print to stdout."""
    # Phase 1: calibrate ambient noise for 0.5s
    calibration_rms = []

    def cal_callback(indata, frames, time_info, status):
        calibration_rms.append(np.sqrt(np.mean(indata ** 2)))

    audio_dev = find_audio_device()
    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=cal_callback, device=audio_dev,
    )
    print("Calibrating mic...", file=sys.stderr, end=" ", flush=True)
    stream.start()
    sd.sleep(500)
    stream.stop()
    stream.close()

    ambient = np.mean(calibration_rms) if calibration_rms else 0.01
    speech_threshold = ambient * 1.5 + 0.01
    print(f"ambient={ambient:.4f}, threshold={speech_threshold:.4f}", file=sys.stderr, flush=True)

    # Phase 2: record until silence after speech
    audio_buffer = []
    is_recording = True
    speech_detected = False
    silence_frames = 0
    # ~64ms per callback at 16kHz/1024 blocksize, 30 frames ≈ 2s
    SILENCE_LIMIT = 30

    def audio_callback(indata, frames, time_info, status):
        nonlocal speech_detected, silence_frames, is_recording
        audio_buffer.append(indata.copy())
        rms = np.sqrt(np.mean(indata ** 2))
        if rms > speech_threshold:
            speech_detected = True
            silence_frames = 0
        elif speech_detected:
            silence_frames += 1
            if silence_frames >= SILENCE_LIMIT:
                is_recording = False

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=audio_callback, device=audio_dev,
    )

    print("Speak now... (stops after 2s of silence)", file=sys.stderr, flush=True)
    stream.start()

    try:
        while is_recording:
            sd.sleep(100)
    except KeyboardInterrupt:
        pass
    finally:
        stream.stop()
        stream.close()

    if not audio_buffer or not speech_detected:
        return

    audio = np.concatenate(audio_buffer, axis=0).flatten()
    print("Transcribing...", file=sys.stderr, flush=True)
    segments, _ = model.transcribe(audio, language=language)
    text = " ".join(seg.text for seg in segments).strip()
    if text:
        print(text)


def main():
    hw_device, hw_compute, hw_model = pick_defaults()

    parser = argparse.ArgumentParser(description="Push-to-talk dictation")
    parser.add_argument(
        "--key", default="RIGHTCTRL",
        help="Trigger key name without KEY_ prefix (default: RIGHTCTRL)",
    )
    parser.add_argument(
        "--model", default=hw_model,
        help=f"Whisper model size: tiny, base, small, medium, large-v3 (default: {hw_model})",
    )
    parser.add_argument("--device", help="Input device path (e.g. /dev/input/event3)")
    parser.add_argument("--list-devices", action="store_true", help="List input devices")
    parser.add_argument("--language", default="en", help="Language code (default: en)")
    parser.add_argument("--cpu", action="store_true", help="Force CPU inference")
    parser.add_argument("--once", action="store_true",
        help="Record once until silence, print transcription to stdout, and exit")
    args = parser.parse_args()

    if args.list_devices:
        list_devices()
        return

    # Hardware setup
    if args.cpu:
        device, compute = "cpu", "int8"
    else:
        device, compute = hw_device, hw_compute

    if args.once:
        print(f"Loading whisper model '{args.model}' on {device} ({compute})...",
              file=sys.stderr, flush=True)
        model = WhisperModel(args.model, device=device, compute_type=compute)
        run_once(model, args.language)
        return

    # Resolve key code
    key_name = f"KEY_{args.key.upper()}"
    key_code = getattr(ecodes, key_name, None)
    if key_code is None:
        print(f"Unknown key: {key_name}")
        sys.exit(1)

    # Find keyboards
    if args.device:
        keyboards = [evdev.InputDevice(args.device)]
    else:
        keyboards = find_keyboards()
        if not keyboards:
            print("No keyboard found. Try --list-devices and --device.")
            sys.exit(1)

    print(f"Loading whisper model '{args.model}' on {device} ({compute})...")
    model = WhisperModel(args.model, device=device, compute_type=compute)

    # Open persistent audio stream
    audio_dev = find_audio_device()
    audio_buffer = []
    is_recording = False

    def audio_callback(indata, frames, time_info, status):
        if is_recording:
            audio_buffer.append(indata.copy())

    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=1, dtype="float32",
        callback=audio_callback, device=audio_dev,
    )
    stream.start()

    print("Listening on:")
    for kbd in keyboards:
        print(f"  {kbd.name} ({kbd.path})")
    print(f"Hold [{args.key.upper()}] to record, release to transcribe.")
    print(f"Ctrl+C to quit.\n")

    selector = DefaultSelector()
    for kbd in keyboards:
        selector.register(kbd, EVENT_READ)

    try:
        while True:
            for sel_key, _ in selector.select():
                dev = sel_key.fileobj
                for event in dev.read():
                    if event.type != ecodes.EV_KEY:
                        continue
                    key_event = evdev.categorize(event)
                    if key_event.scancode != key_code:
                        continue

                    if key_event.keystate == evdev.KeyEvent.key_down and not is_recording:
                        audio_buffer.clear()
                        is_recording = True
                        print("● Recording...", end="", flush=True)

                    elif key_event.keystate == evdev.KeyEvent.key_up and is_recording:
                        is_recording = False

                        if not audio_buffer:
                            print(" (no audio captured)\n")
                            continue

                        audio = np.concatenate(audio_buffer, axis=0).flatten()
                        duration = len(audio) / SAMPLE_RATE
                        print(f" [{duration:.1f}s] transcribing...", end="", flush=True)

                        segments, _ = model.transcribe(audio, language=args.language)
                        text = " ".join(seg.text for seg in segments).strip()

                        if text:
                            subprocess.run(["wl-copy", text])
                            print(f" done. [copied]\n> {text}\n")
                        else:
                            print(" (no speech detected)\n")

    except KeyboardInterrupt:
        print("\nStopping.")
    finally:
        stream.stop()
        stream.close()


if __name__ == "__main__":
    main()
